{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Text Acquisition and Pre-processing\n",
    "\n",
    "In this assignment you will practice obtaining, extracting, cleaning and pre-processing text from an online source. The objective is to obtain the text from a web page and generate a **pandas** DataFrame containing the text segmented, tokenized and with different types of linguistic annotations.\n",
    "\n",
    "You will work with the following objects and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Text Extraction   - [3 Marks]\n",
    "\n",
    "The text you are going to work with corresponds to the following post from the Food and Agriculture Organization of the United Nations website: [World food prices dip in December](https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en).\n",
    "\n",
    "In a more realistic scenario, you should download the html document yourself. This could be done with the following code snippet:\n",
    "\n",
    ">```python\n",
    "import requests\n",
    "URL = \"https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en\"\n",
    "page = requests.get(URL)\n",
    "html_content = page.content\n",
    "\n",
    "However, for this assignment, you are provided with the downloaded document. The file`world-food-prices.html` can be found in the same directory as this notebook and it can be opened as a regular text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> <title>\\n\\tWorld food prices dip in December\\n</title> <script src=\"/ScriptResource.axd?d=okuX3IVIBwfJlfEQK32K3hu4wA2qYZOscmtsXGLNMaT1SeSa2ByRKpPz9pkmicdQmLZjrfXbzQg-t-PYtREZ1mv-AHy-XqG8V1C8KEuJc1LwVjfZ2AWtsXusqOzwjxwAkWajaiTob5rdLJ_1Q_rhyISygdJ2WS4kb3-Mf0bSt_7dAdqZ2JnDovQKGlnv0vvH0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"/ScriptResource.axd?d=ePnjFy9PuY6CB3GWMX-b_9Fw4jG3rW51lh6cTRiQ1f_9YOhRVOpDf4gVRQwVzn4JRlDVp-Aj_GWhYCgMY8uVHBZj_w4a27EVOxonvJSMs3yERFILsgdOHu7up3GVU-jExdmK0YWhyY1E0W4ye5rzFrSYUigZQBN7nFt18-5XwfQs2ZTBZ5-Na5q3Phaw58Dx0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"https://cse.google.com/cse.js?cx=018170620143701104933%3Aqq82jsfba7w\" type=\"text/javascript\"></script><link href=\"/ResourcePackages/FAO/assets/dist/css/bootstrap.min.css?v=5.2.0&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <link href=\"/ResourcePackages/FAO/assets/dist/css/fao-theme.min.css?v=2.6.6&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <!-- Google Tag Manager -->\\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\\'gtm.start\\':\\nnew Date().getTime(),event:\\'gtm.js\\'});var f=d.getElementsByTagName(s)[0],\\nj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';j.async=true;j.src=\\n\\'https://www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n})(window,document,\\'script\\',\\'d'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"world-food-prices.html\", encoding=\"utf8\") as html_file:\n",
    "    html_content = html_file.read()\n",
    "html_content[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    " As you can see the document contains a lot of html tags as well as some **javascript** code. The text also includes fields that are not of interest, such as the navigation menu of the web page. The goal of the first step in this assignment is to extract only the text from the body of the post.   \n",
    "\n",
    "To do this, you must complete the code for the `extract_text` function. This function should parse the content of the html document using the **BeatifulSoup** library, find the html element containing the text of the body of the post, and extract such text. The body of the post is contained by the element with the following **id**: `\"Contentplaceholder1_C011_Col00\"`. Review the [BeautifullSoup documentation](https://beautiful-soup-4.readthedocs.io/en/latest/index.html) to learn how to perform these steps.\n",
    "\n",
    "\n",
    "The function must return the text extracted of which the first 579 characters should look like this:\n",
    "\n",
    "\n",
    "><pre>'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(html_content):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    post_text = soup.find('div',{'id':\"Contentplaceholder1_C011_Col00\"}).get_text()\n",
    "    return post_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = extract_text(html_content)\n",
    "text[:580]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Text Cleanup  - [3 Marks]\n",
    "\n",
    " The text extracted by `extract_text` is not still ready to use. It contains several newline characters and additional spaces that make the text noisy. In the next step of the assignment, you must complete the code for the function `clean_text`. The function should take the text and delete all those newline characters and extra blank spaces. The function should also add a period to the end of those sentences that do not originally contain it, for example, `World food prices dip in December` or `06/01/2023`.\n",
    "\n",
    "You can solve this exercise using the **Python** built-in [string methods](https://docs.python.org/3.9/library/stdtypes.html?highlight=replace#str), such as `replace`, or by [regular expressions](https://docs.python.org/3.9/library/re.html?highlight=re#module-re).\n",
    "\n",
    "The `extract_text` function must return the cleaned text of which the first 499 characters should look like this:\n",
    "\n",
    ">'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    intermediate_text = text.split('\\n')\n",
    "\n",
    "    cleaned_text = ''\n",
    "    for element in intermediate_text:\n",
    "        stripped_element = element.strip() # removes leading and trailing spaces\n",
    "        if stripped_element!='': # checks for empty('') character and does not consider it\n",
    "            if stripped_element[len(stripped_element)-1] not in ('.','!','?') : # checks if the element has boundary markers already(.,!,?)\n",
    "                cleaned_text+=stripped_element+'. '\n",
    "            else:\n",
    "                cleaned_text+= stripped_element+' '\n",
    "\n",
    "    return cleaned_text\n",
    "    #pass\n",
    "\n",
    "clean_text(text)[:499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = clean_text(text)\n",
    "cleaned_text[:499]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Pre-processing  - [3 Marks]\n",
    "\n",
    "Once the text has been extracted and cleaned up, the next step you must take is to pre-process it. For this, in this assignment, you are going to use the [spaCy](https://spacy.io/) library. This library is an advanced NLP toolkit that allows to execute various pre-processing steps as well as different NLP tasks. **spaCy** provides trained [pipelines](https://spacy.io/usage/processing-pipelines) for a variety of languages that can be installed as individual **Python** modules and include [linguistic featues](https://spacy.io/usage/linguistic-features) such as:\n",
    "\n",
    "- Sentence Segmentation\n",
    "- Tokenization\n",
    "- Stemming and Lemmatization\n",
    "- Stopwords\n",
    "- Part-of-speech tagging\n",
    "- Syntactic dependency parsing\n",
    "- Named Entity Recognition\n",
    "- Word Embeddings\n",
    "\n",
    "In this exercise, you will work with the [English pipeline optimized for CPU](https://spacy.io/models/en#en_core_web_sm) that can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    " You must complete the code for the `preprocess_text` function. This function takes the text and a **spaCy** pipeline as input and should run that pipeline on the text. The function must return a [Doc](https://spacy.io/api/doc) object. Check the [spaCy 101](https://spacy.io/usage/spacy-101) documentation to learn how to apply the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World NOUN compound\n",
      "food NOUN compound\n",
      "prices NOUN nsubj\n",
      "dip VERB ROOT\n",
      "in ADP prep\n",
      "December PROPN pobj\n",
      ". PUNCT punct\n",
      "FAO PROPN compound\n",
      "Food PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nsubj\n",
      "ends VERB ROOT\n",
      "2022 NUM dobj\n",
      "lower ADJ amod\n",
      "than ADP prep\n",
      "a DET det\n",
      "year NOUN npadvmod\n",
      "earlier ADV pcomp\n",
      ". PUNCT punct\n",
      "A DET det\n",
      "farmer NOUN ROOT\n",
      "in ADP prep\n",
      "Sicily ADV pcomp\n",
      "carrying VERB pcomp\n",
      "wheat NOUN compound\n",
      "seeds NOUN dobj\n",
      ". PUNCT punct\n",
      "© ADJ amod\n",
      "FAO PROPN nmod\n",
      "/ SYM punct\n",
      "Giorgio PROPN compound\n",
      "Cosulich PROPN ROOT\n",
      ". PUNCT punct\n",
      "06/01/2023 NUM ROOT\n",
      ". PUNCT punct\n",
      "Rome PROPN nsubj\n",
      "– PUNCT punct\n",
      "The DET det\n",
      "index NOUN nsubj\n",
      "of ADP prep\n",
      "world NOUN compound\n",
      "food NOUN compound\n",
      "prices NOUN pobj\n",
      "dipped VERB ccomp\n",
      "for ADP prep\n",
      "the DET det\n",
      "ninth ADJ amod\n",
      "consecutive ADJ amod\n",
      "month NOUN pobj\n",
      "in ADP prep\n",
      "December PROPN pobj\n",
      "2022 NUM nummod\n",
      ", PUNCT punct\n",
      "declining VERB advcl\n",
      "by ADP prep\n",
      "1.9 NUM nummod\n",
      "percent NOUN pobj\n",
      "from ADP prep\n",
      "the DET det\n",
      "previous ADJ amod\n",
      "month NOUN pobj\n",
      ", PUNCT punct\n",
      "the DET det\n",
      "Food PROPN nmod\n",
      "and CCONJ cc\n",
      "Agriculture PROPN conj\n",
      "Organization PROPN nsubj\n",
      "of ADP prep\n",
      "the DET det\n",
      "United PROPN compound\n",
      "Nations PROPN pobj\n",
      "( PUNCT punct\n",
      "FAO PROPN appos\n",
      ") PUNCT punct\n",
      "reported VERB ROOT\n",
      "today NOUN npadvmod\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "FAO PROPN compound\n",
      "Food PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nsubj\n",
      "averaged VERB ROOT\n",
      "132.4 NUM nummod\n",
      "points NOUN dobj\n",
      "in ADP prep\n",
      "December PROPN pobj\n",
      ", PUNCT punct\n",
      "1.0 NUM nummod\n",
      "percent NOUN npadvmod\n",
      "below ADP prep\n",
      "its PRON poss\n",
      "value NOUN pobj\n",
      "a DET det\n",
      "year NOUN npadvmod\n",
      "earlier ADV advmod\n",
      ". PUNCT punct\n",
      "However ADV advmod\n",
      ", PUNCT punct\n",
      "for ADP prep\n",
      "2022 NUM pobj\n",
      "as ADP prep\n",
      "a DET det\n",
      "whole NOUN pobj\n",
      ", PUNCT punct\n",
      "the DET det\n",
      "index NOUN nsubj\n",
      ", PUNCT punct\n",
      "which PRON nsubj\n",
      "tracks VERB relcl\n",
      "monthly ADJ amod\n",
      "changes NOUN dobj\n",
      "in ADP prep\n",
      "the DET det\n",
      "international ADJ amod\n",
      "prices NOUN pobj\n",
      "of ADP prep\n",
      "commonly ADV advmod\n",
      "- PUNCT punct\n",
      "traded VERB amod\n",
      "food NOUN compound\n",
      "commodities NOUN pobj\n",
      ", PUNCT punct\n",
      "averaged VERB ROOT\n",
      "143.7 NUM nummod\n",
      "points NOUN dobj\n",
      ", PUNCT punct\n",
      "14.3 NUM nummod\n",
      "percent NOUN npadvmod\n",
      "higher ADJ amod\n",
      "than ADP prep\n",
      "the DET det\n",
      "average ADJ amod\n",
      "value NOUN pobj\n",
      "over ADP prep\n",
      "2021 NUM pobj\n",
      ". PUNCT punct\n",
      "“ PUNCT punct\n",
      "Calmer ADJ amod\n",
      "food NOUN compound\n",
      "commodity NOUN compound\n",
      "prices NOUN nsubj\n",
      "are AUX ccomp\n",
      "welcome ADJ acomp\n",
      "after ADP prep\n",
      "two NUM nummod\n",
      "very ADV advmod\n",
      "volatile ADJ amod\n",
      "years NOUN pobj\n",
      ", PUNCT punct\n",
      "” PUNCT punct\n",
      "said VERB ROOT\n",
      "FAO PROPN compound\n",
      "Chief PROPN compound\n",
      "Economist PROPN compound\n",
      "Maximo PROPN compound\n",
      "Torero PROPN nsubj\n",
      ". PUNCT punct\n",
      "“ PUNCT punct\n",
      "It PRON nsubj\n",
      "is AUX ROOT\n",
      "important ADJ acomp\n",
      "to PART aux\n",
      "remain VERB xcomp\n",
      "vigilant ADJ acomp\n",
      "and CCONJ cc\n",
      "keep VERB conj\n",
      "a DET det\n",
      "strong ADJ amod\n",
      "focus NOUN dobj\n",
      "on ADP prep\n",
      "mitigating VERB pcomp\n",
      "global ADJ amod\n",
      "food NOUN compound\n",
      "insecurity NOUN dobj\n",
      "given VERB prep\n",
      "that DET det\n",
      "world NOUN compound\n",
      "food NOUN compound\n",
      "prices NOUN pobj\n",
      "remain VERB conj\n",
      "at ADP prep\n",
      "elevated ADJ amod\n",
      "levels NOUN pobj\n",
      ", PUNCT punct\n",
      "with ADP prep\n",
      "many ADJ amod\n",
      "staples NOUN pobj\n",
      "near ADP prep\n",
      "record NOUN compound\n",
      "highs NOUN pobj\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "with SCONJ mark\n",
      "prices NOUN nsubj\n",
      "of ADP prep\n",
      "rice NOUN pobj\n",
      "increasing VERB conj\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "still ADV advmod\n",
      "many ADJ amod\n",
      "risks NOUN nsubj\n",
      "associated VERB acl\n",
      "with ADP prep\n",
      "future ADJ amod\n",
      "supplies NOUN nmod\n",
      "” PUNCT punct\n",
      "Vegetable PROPN compound\n",
      "oil NOUN compound\n",
      "world NOUN compound\n",
      "quotations NOUN pobj\n",
      "led VERB conj\n",
      "the DET det\n",
      "decrease NOUN dobj\n",
      ", PUNCT punct\n",
      "with ADP prep\n",
      "the DET det\n",
      "FAO PROPN compound\n",
      "Vegetable PROPN compound\n",
      "Oil PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN pobj\n",
      "down ADV advmod\n",
      "6.7 NUM nummod\n",
      "percent NOUN npadvmod\n",
      "from ADP prep\n",
      "November PROPN pobj\n",
      "to PART aux\n",
      "reach VERB advcl\n",
      "its PRON poss\n",
      "lowest ADJ amod\n",
      "level NOUN dobj\n",
      "since SCONJ prep\n",
      "February PROPN pobj\n",
      "2021 NUM nummod\n",
      ". PUNCT punct\n",
      "International ADJ amod\n",
      "quotations NOUN nsubj\n",
      "for ADP prep\n",
      "palm NOUN pobj\n",
      ", PUNCT punct\n",
      "soy NOUN conj\n",
      ", PUNCT punct\n",
      "rapeseed NOUN conj\n",
      "and CCONJ cc\n",
      "sunflowerseed ADJ amod\n",
      "oils NOUN conj\n",
      "all PRON appos\n",
      "declined VERB ROOT\n",
      "in ADP prep\n",
      "December PROPN pobj\n",
      ", PUNCT punct\n",
      "driven VERB advcl\n",
      "by ADP agent\n",
      "subdued VERB amod\n",
      "global ADJ amod\n",
      "import NOUN compound\n",
      "demand NOUN pobj\n",
      "and CCONJ cc\n",
      "prospects NOUN conj\n",
      "of ADP prep\n",
      "seasonally ADV advmod\n",
      "rising VERB amod\n",
      "soy NOUN compound\n",
      "oil NOUN compound\n",
      "production NOUN pobj\n",
      "in ADP prep\n",
      "South PROPN compound\n",
      "America PROPN pobj\n",
      "as ADV advmod\n",
      "well ADV advmod\n",
      "as ADP cc\n",
      "declining VERB amod\n",
      "crude ADJ amod\n",
      "oil NOUN compound\n",
      "prices NOUN conj\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "FAO PROPN compound\n",
      "Cereal PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nsubj\n",
      "decreased VERB ROOT\n",
      "1.9 NUM nummod\n",
      "percent NOUN npadvmod\n",
      "from ADP prep\n",
      "November PROPN pobj\n",
      ". PUNCT punct\n",
      "Ongoing ADJ amod\n",
      "harvests NOUN nsubj\n",
      "in ADP prep\n",
      "the DET det\n",
      "southern ADJ amod\n",
      "hemisphere NOUN pobj\n",
      "boosted VERB ROOT\n",
      "wheat NOUN nmod\n",
      "exportable ADJ amod\n",
      "supplies NOUN dobj\n",
      ", PUNCT punct\n",
      "while SCONJ mark\n",
      "strong ADJ amod\n",
      "competition NOUN nsubj\n",
      "from ADP prep\n",
      "Brazil PROPN pobj\n",
      "drove VERB advcl\n",
      "down ADP advmod\n",
      "world NOUN compound\n",
      "maize NOUN compound\n",
      "prices NOUN dobj\n",
      ". PUNCT punct\n",
      "Conversely ADV advmod\n",
      ", PUNCT punct\n",
      "international ADJ amod\n",
      "rice NOUN compound\n",
      "prices NOUN nsubj\n",
      "rose VERB ROOT\n",
      ", PUNCT punct\n",
      "buoyed VERB advcl\n",
      "by ADP agent\n",
      "Asian ADJ amod\n",
      "buying NOUN nmod\n",
      "and CCONJ cc\n",
      "currency NOUN conj\n",
      "appreciation NOUN pobj\n",
      "against ADP prep\n",
      "the DET det\n",
      "United PROPN compound\n",
      "States PROPN compound\n",
      "dollar NOUN pobj\n",
      "for ADP prep\n",
      "exporting VERB amod\n",
      "countries NOUN pobj\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "FAO PROPN compound\n",
      "Meat PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nsubj\n",
      "in ADP prep\n",
      "December PROPN pobj\n",
      "dropped VERB ROOT\n",
      "by ADP prep\n",
      "1.2 NUM nummod\n",
      "percent NOUN pobj\n",
      "from ADP prep\n",
      "November PROPN pobj\n",
      ", PUNCT punct\n",
      "with ADP prep\n",
      "lower ADJ amod\n",
      "world NOUN compound\n",
      "prices NOUN pobj\n",
      "of ADP prep\n",
      "bovine NOUN amod\n",
      "and CCONJ cc\n",
      "poultry NOUN conj\n",
      "meats NOUN pobj\n",
      "outweighing VERB acl\n",
      "higher ADJ amod\n",
      "pig NOUN dobj\n",
      "and CCONJ cc\n",
      "ovine NOUN compound\n",
      "meat NOUN compound\n",
      "prices NOUN conj\n",
      ". PUNCT punct\n",
      "International ADJ amod\n",
      "bovine ADJ compound\n",
      "meat NOUN compound\n",
      "prices NOUN nsubjpass\n",
      "were AUX auxpass\n",
      "impacted VERB ROOT\n",
      "by ADP agent\n",
      "lacklustre ADJ amod\n",
      "global ADJ amod\n",
      "demand NOUN pobj\n",
      "for ADP prep\n",
      "medium ADJ amod\n",
      "- PUNCT punct\n",
      "term NOUN compound\n",
      "supplies NOUN pobj\n",
      ", PUNCT punct\n",
      "while SCONJ mark\n",
      "more ADJ amod\n",
      "- PUNCT punct\n",
      "than ADP prep\n",
      "- PUNCT punct\n",
      "adequate ADJ pobj\n",
      "export NOUN compound\n",
      "supplies NOUN nsubj\n",
      "pushed VERB advcl\n",
      "down ADP prt\n",
      "poultry NOUN compound\n",
      "meat NOUN compound\n",
      "prices NOUN dobj\n",
      ". PUNCT punct\n",
      "Pig ADJ amod\n",
      "meat NOUN compound\n",
      "prices NOUN nsubj\n",
      "rose VERB ccomp\n",
      "on ADP prep\n",
      "the DET det\n",
      "back NOUN pobj\n",
      "of ADP prep\n",
      "strong ADJ amod\n",
      "internal ADJ amod\n",
      "holiday NOUN compound\n",
      "demand NOUN pobj\n",
      ", PUNCT punct\n",
      "especially ADV advmod\n",
      "in ADP prep\n",
      "Europe PROPN pobj\n",
      ", PUNCT punct\n",
      "The DET det\n",
      "FAO PROPN compound\n",
      "Dairy PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nsubj\n",
      "increased VERB ROOT\n",
      "by ADP prep\n",
      "1.2 NUM nummod\n",
      "percent NOUN pobj\n",
      "in ADP prep\n",
      "December PROPN pobj\n",
      ", PUNCT punct\n",
      "following VERB prep\n",
      "five NUM nummod\n",
      "months NOUN pobj\n",
      "of ADP prep\n",
      "consecutive ADJ amod\n",
      "declines NOUN pobj\n",
      ". PUNCT punct\n",
      "Higher ADJ amod\n",
      "international ADJ amod\n",
      "cheese NOUN compound\n",
      "prices NOUN nsubj\n",
      ", PUNCT punct\n",
      "reflecting VERB acl\n",
      "tightening VERB amod\n",
      "market NOUN compound\n",
      "conditions NOUN dobj\n",
      ", PUNCT punct\n",
      "drove VERB ROOT\n",
      "the DET det\n",
      "monthly ADJ amod\n",
      "increase NOUN dobj\n",
      "in ADP prep\n",
      "the DET det\n",
      "index NOUN pobj\n",
      ", PUNCT punct\n",
      "while SCONJ mark\n",
      "international ADJ amod\n",
      "quotations NOUN nsubj\n",
      "for ADP prep\n",
      "butter NOUN nmod\n",
      "and CCONJ cc\n",
      "milk NOUN conj\n",
      "powder NOUN pobj\n",
      "declined VERB advcl\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "FAO PROPN compound\n",
      "Sugar PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nsubj\n",
      "also ADV advmod\n",
      "rose VERB ROOT\n",
      ", PUNCT punct\n",
      "increasing VERB advcl\n",
      "by ADP prep\n",
      "2.4 NUM nummod\n",
      "percent NOUN pobj\n",
      "from ADP prep\n",
      "November PROPN pobj\n",
      ", PUNCT punct\n",
      "mostly ADV advmod\n",
      "due ADJ conj\n",
      "to ADP pcomp\n",
      "concerns NOUN pobj\n",
      "over ADP prep\n",
      "the DET det\n",
      "impact NOUN pobj\n",
      "of ADP prep\n",
      "adverse ADJ amod\n",
      "weather NOUN compound\n",
      "conditions NOUN pobj\n",
      "on ADP prep\n",
      "crop NOUN compound\n",
      "yields NOUN pobj\n",
      "in ADP prep\n",
      "India PROPN pobj\n",
      "and CCONJ cc\n",
      "sugarcane ADJ amod\n",
      "crushing VERB amod\n",
      "delays NOUN conj\n",
      "in ADP prep\n",
      "Thailand PROPN pobj\n",
      "and CCONJ cc\n",
      "Australia PROPN conj\n",
      ". PUNCT punct\n",
      "Looking VERB csubj\n",
      "back ADV advmod\n",
      "on ADP prep\n",
      "2022As NUM pobj\n",
      "noted VERB parataxis\n",
      ", PUNCT punct\n",
      "the DET det\n",
      "FAO PROPN compound\n",
      "Food PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN compound\n",
      "average NOUN nsubj\n",
      "over ADP prep\n",
      "2022 NUM pobj\n",
      "was AUX ROOT\n",
      "notably ADV advmod\n",
      "higher ADJ acomp\n",
      "than ADP prep\n",
      "the DET det\n",
      "previous ADJ amod\n",
      "year NOUN pobj\n",
      ", PUNCT punct\n",
      "which PRON nsubj\n",
      "on ADP relcl\n",
      "top NOUN pobj\n",
      "of ADP prep\n",
      "large ADJ amod\n",
      "increases NOUN pobj\n",
      "in ADP prep\n",
      "2021 NUM pobj\n",
      "catalyzed ADJ amod\n",
      "significant ADJ amod\n",
      "strains NOUN pobj\n",
      "and CCONJ cc\n",
      "food NOUN compound\n",
      "security NOUN compound\n",
      "concerns NOUN conj\n",
      "for ADP prep\n",
      "lower ADJ amod\n",
      "- PUNCT punct\n",
      "income NOUN nmod\n",
      "food NOUN npadvmod\n",
      "- PUNCT punct\n",
      "importing VERB amod\n",
      "countries NOUN pobj\n",
      "and CCONJ cc\n",
      "the DET det\n",
      "adoption NOUN conj\n",
      ", PUNCT punct\n",
      "inspired VERB acl\n",
      "by ADP agent\n",
      "FAO PROPN pobj\n",
      ", PUNCT punct\n",
      "of ADP prep\n",
      "a DET det\n",
      "“ PUNCT punct\n",
      "Food PROPN nmod\n",
      "Shock PROPN nmod\n",
      "Window PROPN nmod\n",
      "” PUNCT punct\n",
      "lending NOUN compound\n",
      "facility NOUN pobj\n",
      "by ADP prep\n",
      "the DET det\n",
      "International PROPN compound\n",
      "Monetary PROPN compound\n",
      "Fund PROPN pobj\n",
      ". PUNCT punct\n",
      "World NOUN compound\n",
      "prices NOUN nsubj\n",
      "of ADP prep\n",
      "wheat NOUN pobj\n",
      "and CCONJ cc\n",
      "maize NOUN conj\n",
      "reached VERB ROOT\n",
      "record ADJ compound\n",
      "highs NOUN dobj\n",
      "over ADP prep\n",
      "the DET det\n",
      "year NOUN pobj\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "average ADJ amod\n",
      "value NOUN nsubj\n",
      "of ADP prep\n",
      "the DET det\n",
      "FAO PROPN compound\n",
      "Vegetable PROPN compound\n",
      "Oil PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN pobj\n",
      "for ADP prep\n",
      "all PRON pobj\n",
      "of ADP prep\n",
      "2022 NUM pobj\n",
      "reached VERB ROOT\n",
      "a DET det\n",
      "new ADJ amod\n",
      "record NOUN compound\n",
      "high ADV dobj\n",
      ", PUNCT punct\n",
      "while SCONJ mark\n",
      "the DET det\n",
      "FAO PROPN compound\n",
      "Dairy PROPN compound\n",
      "Price PROPN compound\n",
      "Index PROPN nmod\n",
      "and CCONJ cc\n",
      "Meat PROPN compound\n",
      "Price PROPN conj\n",
      "Index PROPN nsubj\n",
      "marked VERB advcl\n",
      "their PRON poss\n",
      "highest ADJ amod\n",
      "full ADJ amod\n",
      "- PUNCT punct\n",
      "year NOUN compound\n",
      "levels NOUN dobj\n",
      "since SCONJ mark\n",
      "1990.More ADJ amod\n",
      "details NOUN nsubj\n",
      "are AUX advcl\n",
      "available ADJ acomp\n",
      "here ADV advmod\n",
      ". PUNCT punct\n",
      "More ADJ ROOT\n",
      "on ADP prep\n",
      "this DET det\n",
      "topic NOUN pobj\n",
      ". PUNCT punct\n",
      "FAO PROPN compound\n",
      "Food PROPN compound\n",
      "Price PROPN compound\n",
      "IndexFAO NOUN poss\n",
      "'s PART case\n",
      "most ADV advmod\n",
      "recent ADJ amod\n",
      "Cereal PROPN nmod\n",
      "Supply PROPN nmod\n",
      "and CCONJ cc\n",
      "Demand PROPN conj\n",
      "BriefAMIS NOUN ROOT\n",
      ": PUNCT punct\n",
      "Market PROPN compound\n",
      "MonitorAgricultural PROPN compound\n",
      "Market PROPN compound\n",
      "Information PROPN compound\n",
      "System PROPN ROOT\n",
      "( PUNCT punct\n",
      "AMIS)FAO PROPN compound\n",
      "Markets PROPN appos\n",
      "and CCONJ cc\n",
      "Trade PROPN conj\n",
      ". PUNCT punct\n",
      "Contact NOUN ROOT\n",
      ". PUNCT punct\n",
      "Christopher PROPN compound\n",
      "Emsden PROPN ROOT\n",
      ". PUNCT punct\n",
      "FAO PROPN compound\n",
      "News PROPN ROOT\n",
      "and CCONJ cc\n",
      "Media PROPN conj\n",
      "( PUNCT punct\n",
      "Rome PROPN appos\n",
      ") PUNCT punct\n",
      ". PUNCT punct\n",
      "( PUNCT punct\n",
      "+39 PROPN ROOT\n",
      ") PUNCT punct\n",
      "06 NUM nummod\n",
      "570 NUM nummod\n",
      "53291 NUM appos\n",
      ". PUNCT punct\n",
      "[ X punct\n",
      "email NOUN nsubj\n",
      "  SPACE dep\n",
      "protected VERB ROOT\n",
      "] PUNCT punct\n",
      ". PUNCT punct\n",
      "FAO PROPN compound\n",
      "News PROPN ROOT\n",
      "and CCONJ cc\n",
      "Media PROPN conj\n",
      ". PUNCT punct\n",
      "( PUNCT punct\n",
      "+39 PROPN ROOT\n",
      ") PUNCT punct\n",
      "06 NUM nummod\n",
      "570 NUM nummod\n",
      "53625 NUM appos\n",
      ". PUNCT punct\n",
      "[ X punct\n",
      "email NOUN nsubj\n",
      "  SPACE dep\n",
      "protected VERB ROOT\n",
      "] PUNCT punct\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "def process_text(text, nlp):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    doc_obj = nlp(text)\n",
    "    return doc_obj\n",
    "    #pass\n",
    "doc = process_text(cleaned_text, nlp)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = process_text(cleaned_text, nlp)\n",
    "all(map(doc.has_annotation, [\"LEMMA\", \"POS\", \"ENT_TYPE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Creating a DataFrame  - [3 Marks]\n",
    "\n",
    "In the next exercise, you will create a [pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that will contain some of the linguistic annotations from the `Doc` object obtained in the previous step. Loading the data into a `DataFrame` provides some advantages such as a better integration with other **Python** machine learning libraries or the option to save the data in a csv file.\n",
    "\n",
    "The goal is to create a `DataFrame` that contains a row per each token in the `Doc` and the following columns:\n",
    "- *sent_id*: The id of the sentence the token belongs to. It represents the position of the sentence in the `Doc`, starting by 0.\n",
    "- *token_id*: The id of the token. It represents the position of the token in the sentence, starting by 0.\n",
    "- *text*: The original text of the token.\n",
    "- *lemma*: The lemmatization of the token.\n",
    "- *pos*: The part-of-speech of the token.\n",
    "- *ent*: The entity type of the token returned by the Named Entity Recognition component.\n",
    "\n",
    "You must complete the code for the `to_dataframe` function. This function takes the [Doc](https://spacy.io/api/doc) object and must return the `DataFrame` described above. The function should iterate over the sentences in the `Doc` (each sentence is a [Span](https://spacy.io/api/span) object) and, for each sentence, it should iterate over its tokens (each token is a [Token](https://spacy.io/api/token) object). For each token, `to_dataframe` should obtain the values to fill the *text*, *lemma*, *pos* and *ent* columns of the `DataFrame`. For example, the content of the `DataFrame` for the setence with *sent_id* equal to 1, corresponding to the second sentence in the `Doc`, should look like this:\n",
    "\n",
    "|    |   sent_id |   token_id | text    | lemma   | pos   | ent   |\n",
    "|---:|----------:|-----------:|:--------|:--------|:------|:------|\n",
    "|  7 |         1 |          0 | FAO     | FAO     | PROPN | ORG   |\n",
    "|  8 |         1 |          1 | Food    | Food    | PROPN | ORG   |\n",
    "|  9 |         1 |          2 | Price   | Price   | PROPN | ORG   |\n",
    "| 10 |         1 |          3 | Index   | Index   | PROPN | ORG   |\n",
    "| 11 |         1 |          4 | ends    | end     | VERB  |       |\n",
    "| 12 |         1 |          5 | 2022    | 2022    | NUM   | DATE  |\n",
    "| 13 |         1 |          6 | lower   | low     | ADJ   |       |\n",
    "| 14 |         1 |          7 | than    | than    | ADP   |       |\n",
    "| 15 |         1 |          8 | a       | a       | DET   | DATE  |\n",
    "| 16 |         1 |          9 | year    | year    | NOUN  | DATE  |\n",
    "| 17 |         1 |         10 | earlier | early   | ADV   | DATE  |\n",
    "| 18 |         1 |         11 | .       | .       | PUNCT |       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(doc):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = to_dataframe(doc)\n",
    "df[df.sent_id == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Cutomizing the Tokenizer  - [3 Marks]\n",
    "\n",
    "The default components of a **spaCy** pipeline will not always behave according to the needs of your projects. For example, the default tokenizer of the `en_core_web_sm` pipeline does not always splits dates in `month/day/year` format into `month`, `day` and `year`. This is the case for the sentence with *sent_id* equal to 4 that only includes a date in that format:\n",
    "\n",
    "|    |   sent_id |   token_id | text       | lemma      | pos   | ent   |\n",
    "|---:|----------:|-----------:|:-----------|:-----------|:------|:------|\n",
    "| 32 |         4 |          0 | 06/01/2023 | 06/01/2023 | NUM   |       |\n",
    "| 33 |         4 |          1 | .          | .          | PUNCT |       |\n",
    "\n",
    "The goal of the last exercise of this task is to update the `en_core_web_sm` pipeline with a custom tokenizer that forces the splitting of dates in `month/day/year` format so that the sentence above looks like this:\n",
    "\n",
    "|    |   sent_id |   token_id | text   | lemma   | pos   | ent      |\n",
    "|---:|----------:|-----------:|:-------|:--------|:------|:---------|\n",
    "| 32 |         4 |          0 | 06     | 06      | NUM   | CARDINAL |\n",
    "| 33 |         4 |          1 | /      | /       | SYM   |          |\n",
    "| 34 |         4 |          2 | 01     | 01      | NUM   |          |\n",
    "| 35 |         4 |          3 | /      | /       | SYM   |          |\n",
    "| 36 |         4 |          4 | 2023   | 2023    | NUM   |          |\n",
    "| 37 |         4 |          5 | .      | .       | PUNCT |          |\n",
    "\n",
    "You must complete the code for the `customize_tokenizer` function. The function takes the **spaCy** pipeline as input. It should updated the infixes rules of the tokenizer and return the updated version of the pipeline including the customized tokenizer. The `Tokenizer` must keep the default vocabulary and all the default prefixes, infixes and suffixes rules of the pipeline. You should only update the infixes rules adding a regular expression that captures slash (`/`) characters. The `Tokenizer` should **not** include special cases or rules for token and url matching. Check the [spacy's documentation](https://spacy.io/usage/linguistic-features#native-tokenizers) to learn how to customize the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_tokenizer(nlp):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "customized_nlp = customize_tokenizer(nlp)\n",
    "doc = process_text(cleaned_text, customized_nlp)\n",
    "df = to_dataframe(doc)\n",
    "df[df.sent_id == 4]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
